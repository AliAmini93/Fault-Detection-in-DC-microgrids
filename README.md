# Fault Detection in DC-microgrids
The data is gathered from multiple simulations of DC microgrids using DIgSILENT software. The exported data from each simulation is in the form of 8 discretized variables. consider both voltage and current signals are measured in both positive and negative poles and at both ends of the line, and we want a model in bus 1 to detect and locate the fault on the line so finally we have 8 variables and the sample rate is 50000. We need to detect the internal fault (lines 1-2) from the other external fault using only 7 samples which is 0.14 ms to protect the DC microgrid accurately. 
DWT and FFT were employed for extracting features from the data. Having the extracted features (4 components for each variable in FFT equals 32 features, and, 2 components for each variable in DWT, equals 16 features), the LR (Logistic Regression), LDA (Linear Discriminant Analysis), SVM (Support Vector Machine), RF (Random Forest) and XGBoost (Extreme Gradient Boosting) methods are employed for 2-class classification. In addition, 3 different feature-selection methods were leveraged to select the most useful features out of 32 (in FFT) and 16 (in DWT), named by, Mutual Information(MI), ANOVA F-measure, and Pearson correlation. Furthermore, the raw data(a window of 7 by 8 samples of raw data) is employed for CNN models for spatial and temporal feature extraction and classification. 4 configurations of CNN models with different capacities were used for this purpose. 
The performance assessment is conducted using a (5-2)-fold cross-validation strategy. Within the inner 2-fold, the hyper-parameters of the models (for CNN and ML-based models) are tunned and the feature selection is done (just for ML-based models). This is done using the Grid-search algorithm for ML-based, and Bayesian optimization for the CNN models. In the outer 5-fold using the selected features and tunned hyper-parameters, the performance of the model is evaluated and averaged. The optimal hyper-parameters and the selected features are stored for each fold and model. The final(average) performance of the model in terms of “Accuracy”, “F1-measure” and “F2-measure” are saved in an Excel file based on the models and the feature-selection method.
To evaluate the performance of the models in presence of the noise, the input data is contaminated with Gaussian noise with different SNR values varied from 20,25,30,35,40 and 45 dB. The results of the models are reported only when the test data are corrupted with noise. So the model were not trained using the noisy data. The feature selection and hyper-parameter tunning is performed only using the clean data. In the outer 5-fold the test data are tested using the above-mentioned noisy data. 










Data was procured from numerous simulations of Direct Current (DC) microgrids using DIgSILENT software. The software generated data from each simulation containing eight discretized variables. These variables were derived from voltage and current signals measured at both the positive and negative poles and at both ends of the line. One of the primary objectives was to develop a model at bus 1 that could detect and locate faults on the line. The sample rate for these variables was set at 50000, with the aim of identifying an internal fault (lines 1-2) from other external faults using only seven samples, equivalent to 0.14 milliseconds. This was to ensure precise protection of the DC microgrid.
Feature extraction from the data was achieved using Discrete Wavelet Transform (DWT) and Fast Fourier Transform (FFT). The FFT yielded four components for each variable, amounting to 32 features, while the DWT produced two components for each variable, resulting in 16 features. Five machine learning methods, Logistic Regression (LR), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGBoost), were then utilized for two-class classification. Moreover, three different feature-selection methods, Mutual Information (MI), ANOVA F-measure, and Pearson correlation, were implemented to select the most valuable features from the 32 (FFT) and 16 (DWT). The raw data, represented by a window of seven by eight samples, was used for Convolutional Neural Networks (CNN) models for spatial and temporal feature extraction and classification. Four configurations of CNN models with different capacities were employed for this purpose.
The effectiveness of the models was evaluated using a (5-2)-fold cross-validation strategy. In the inner two-fold, the hyper-parameters of the models (for CNN and ML-based models) were tuned, and feature selection was performed (only for ML-based models). This was achieved using the Grid-search algorithm for ML-based models and Bayesian optimization for the CNN models. In the outer five-fold, the performance of the model was evaluated and averaged using the selected features and tuned hyper-parameters. The optimal hyper-parameters and selected features were stored for each fold and model. The final performance of the model, in terms of "Accuracy", "F1-measure", and "F2-measure", was documented in an Excel file based on the models and the feature-selection method.
To assess the performance of the models under noisy conditions, the input data was contaminated with Gaussian noise at different Signal-to-Noise Ratio (SNR) values, ranging from 20 to 45 decibels. The model results were only reported when the test data were corrupted with noise. The models were not trained using noisy data. The feature selection and hyper-parameter tuning were conducted using clean data. In the outer 5-fold, the test data were evaluated using the aforementioned noisy data. 
This process was undertaken to evaluate the robustness of the methods in conditions with noise interference. The outcomes of this part of the study are stored in a folder named "Noisy Evaluation". Conversely, the results from the evaluation of clean data are documented in a folder titled "Without Noise Evaluation".
