{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qZ3dJgeDPycR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691587156636,"user_tz":-210,"elapsed":3117,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"25fc0c55-9f01-411a-ccf0-0806f63586c3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eH14YbVJF2jJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691587156638,"user_tz":-210,"elapsed":14,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"cf564377-1152-4071-c80c-5051bd07a957"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Ali Sobhani Thesis/Noisy/DWT\n"]}],"source":["cd '/content/drive/MyDrive/Ali Sobhani Thesis/Noisy/DWT'"]},{"cell_type":"code","source":["'''import numpy as np\n","from sklearn.experimental import enable_halving_search_cv  # noqa\n","from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import fbeta_score\n","from scipy.stats import pearsonr\n","\n","def pearsonr_scorer(X, y):\n","    scores, pvalues = [], []\n","    for column in X.T:\n","        score, pvalue = pearsonr(column, y)\n","        scores.append(abs(score))\n","        pvalues.append(pvalue)\n","    return np.array(scores), np.array(pvalues)\n","\n","feature_selection = SelectKBest(score_func=pearsonr_scorer)\n","feature_names = ['IP1_C1', 'IP1_C2', 'IP1_C3','IP1_C4','IN1_C1', 'IN1_C2', 'IN1_C3', 'IN1_C4',\n","                    'IP2_C1', 'IP2_C2', 'IP2_C3', 'IP2_C4', 'IN2_C1', 'IN2_C2', 'IN2_C3', 'IN2_C4',\n","                    'VP1_C1', 'VP1_C2', 'VP1_C3', 'VP1_C4', 'VN1_C1', 'VN1_C2', 'VN1_C3', 'VN1_C4',\n","                    'VP2_C1', 'VP2_C2', 'VP2_C3', 'VP2_C4', 'VN2_C1', 'VN2_C2', 'VN2_C3', 'VN2_C4']\n","\n","X = np.load('X.npy')\n","Y = np.load('Y.npy')\n","\n","rf = RandomForestClassifier()\n","\n","pipeline = Pipeline([\n","    ('feature_selection', feature_selection),\n","    ('rf', rf)\n","])\n","\n","param_grid = {\n","    'feature_selection__k': list(range(1, X.shape[1] + 1)),\n","    'rf__n_estimators': [10, 50, 100, 200, 500],\n","    'rf__max_depth': [None, 10, 20, 30, 40, 50],\n","    'rf__min_samples_split': [2, 5, 10],\n","    'rf__min_samples_leaf': [1, 2, 4],\n","    'rf__bootstrap': [True, False]\n","}\n","\n","outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n","inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=13)\n","\n","grid_search = HalvingGridSearchCV(pipeline, param_grid, cv=inner_cv, scoring='accuracy')\n","\n","best_scores = {'accuracy': [], 'f2': []}\n","best_params = []\n","all_selected_names = []\n","\n","for train_idx, test_idx in outer_cv.split(X, Y):\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = Y[train_idx], Y[test_idx]\n","\n","    grid_search.fit(X_train, y_train)\n","    best_params.append(grid_search.best_params_)\n","\n","    best_scores['accuracy'].append(grid_search.best_score_)\n","\n","    y_pred = grid_search.predict(X_test)\n","\n","    f2 = fbeta_score(y_test, y_pred, beta=2)\n","    best_scores['f2'].append(f2)\n","\n","    selected_features = grid_search.best_estimator_.named_steps['feature_selection']\n","    selected_names = [feature_names[i] for i in selected_features.get_support(indices=True)]\n","    all_selected_names.append(selected_names)\n","\n","average_best_scores = {scoring: np.mean(scores) for scoring, scores in best_scores.items()}\n","print(f\"Average best scores: {average_best_scores}\")\n","'''"],"metadata":{"id":"WYiiMD9oGuV0","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1691587156638,"user_tz":-210,"elapsed":10,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"689e9842-1039-4cba-9119-a058500f5f8e"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import numpy as np\\nfrom sklearn.experimental import enable_halving_search_cv  # noqa\\nfrom sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\\nfrom sklearn.feature_selection import SelectKBest\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import fbeta_score\\nfrom scipy.stats import pearsonr\\n\\ndef pearsonr_scorer(X, y):\\n    scores, pvalues = [], []\\n    for column in X.T:\\n        score, pvalue = pearsonr(column, y)\\n        scores.append(abs(score))\\n        pvalues.append(pvalue)\\n    return np.array(scores), np.array(pvalues)\\n\\nfeature_selection = SelectKBest(score_func=pearsonr_scorer)\\nfeature_names = [\\'IP1_C1\\', \\'IP1_C2\\', \\'IP1_C3\\',\\'IP1_C4\\',\\'IN1_C1\\', \\'IN1_C2\\', \\'IN1_C3\\', \\'IN1_C4\\',\\n                    \\'IP2_C1\\', \\'IP2_C2\\', \\'IP2_C3\\', \\'IP2_C4\\', \\'IN2_C1\\', \\'IN2_C2\\', \\'IN2_C3\\', \\'IN2_C4\\',\\n                    \\'VP1_C1\\', \\'VP1_C2\\', \\'VP1_C3\\', \\'VP1_C4\\', \\'VN1_C1\\', \\'VN1_C2\\', \\'VN1_C3\\', \\'VN1_C4\\',\\n                    \\'VP2_C1\\', \\'VP2_C2\\', \\'VP2_C3\\', \\'VP2_C4\\', \\'VN2_C1\\', \\'VN2_C2\\', \\'VN2_C3\\', \\'VN2_C4\\']\\n\\nX = np.load(\\'X.npy\\')\\nY = np.load(\\'Y.npy\\')\\n\\nrf = RandomForestClassifier()\\n\\npipeline = Pipeline([\\n    (\\'feature_selection\\', feature_selection),\\n    (\\'rf\\', rf)\\n])\\n\\nparam_grid = {\\n    \\'feature_selection__k\\': list(range(1, X.shape[1] + 1)),\\n    \\'rf__n_estimators\\': [10, 50, 100, 200, 500],\\n    \\'rf__max_depth\\': [None, 10, 20, 30, 40, 50],\\n    \\'rf__min_samples_split\\': [2, 5, 10],\\n    \\'rf__min_samples_leaf\\': [1, 2, 4],\\n    \\'rf__bootstrap\\': [True, False]\\n}\\n\\nouter_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\\ninner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=13)\\n\\ngrid_search = HalvingGridSearchCV(pipeline, param_grid, cv=inner_cv, scoring=\\'accuracy\\')\\n\\nbest_scores = {\\'accuracy\\': [], \\'f2\\': []}\\nbest_params = []\\nall_selected_names = []\\n\\nfor train_idx, test_idx in outer_cv.split(X, Y):\\n    X_train, X_test = X[train_idx], X[test_idx]\\n    y_train, y_test = Y[train_idx], Y[test_idx]\\n\\n    grid_search.fit(X_train, y_train)\\n    best_params.append(grid_search.best_params_)\\n\\n    best_scores[\\'accuracy\\'].append(grid_search.best_score_)\\n\\n    y_pred = grid_search.predict(X_test)\\n\\n    f2 = fbeta_score(y_test, y_pred, beta=2)\\n    best_scores[\\'f2\\'].append(f2)\\n\\n    selected_features = grid_search.best_estimator_.named_steps[\\'feature_selection\\']\\n    selected_names = [feature_names[i] for i in selected_features.get_support(indices=True)]\\n    all_selected_names.append(selected_names)\\n\\naverage_best_scores = {scoring: np.mean(scores) for scoring, scores in best_scores.items()}\\nprint(f\"Average best scores: {average_best_scores}\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.experimental import enable_halving_search_cv  # noqa\n","from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import fbeta_score\n","from scipy.stats import pearsonr\n","\n","def pearsonr_scorer(X, y):\n","    scores, pvalues = [], []\n","    for column in X.T:\n","        score, pvalue = pearsonr(column, y)\n","        scores.append(abs(score))\n","        pvalues.append(pvalue)\n","    return np.array(scores), np.array(pvalues)\n","\n","feature_selection = SelectKBest(score_func=pearsonr_scorer)\n","feature_names = ['IP1_E1', 'IP1_E2', 'IN1_E1','IN1_E2','IP2_E1', 'IP2_E2', 'IN2_E1', 'IN2_E2',\n","                    'VP1_E1', 'VP1_E2', 'VN1_E1', 'VN1_E2', 'VP2_E1', 'VP2_E2', 'VN2_E1', 'VN2_E2']\n","\n","############################\n","X = np.load('X.npy')\n","Y = np.load('Y.npy')\n","X_20 = np.load('X_DWT_SNR_20.npy')\n","Y_20 = np.load('Y_DWT_SNR_20.npy')\n","X_25 = np.load('X_DWT_SNR_25.npy')\n","Y_25 = np.load('Y_DWT_SNR_25.npy')\n","X_30 = np.load('X_DWT_SNR_30.npy')\n","Y_30 = np.load('Y_DWT_SNR_30.npy')\n","X_35 = np.load('X_DWT_SNR_35.npy')\n","Y_35 = np.load('Y_DWT_SNR_35.npy')\n","X_40 = np.load('X_DWT_SNR_40.npy')\n","Y_40 = np.load('Y_DWT_SNR_40.npy')\n","X_45 = np.load('X_DWT_SNR_45.npy')\n","Y_45 = np.load('Y_DWT_SNR_45.npy')\n","###########################\n","\n","rf = RandomForestClassifier(n_estimators=100)\n","\n","pipeline = Pipeline([\n","    ('feature_selection', feature_selection),\n","    ('rf', rf)\n","])\n","\n","param_grid = {\n","    'feature_selection__k': list(range(1, X.shape[1] + 1)),\n","    'rf__n_estimators': [100, 200, 300],\n","    'rf__max_depth': [None, 30, 50],\n","    'rf__min_samples_split': [2, 5, 10],\n","    'rf__min_samples_leaf': [1, 2, 4],\n","    'rf__bootstrap': [True, False]\n","}\n","\n","outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n","inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=13)\n","\n","grid_search = RandomizedSearchCV(pipeline, param_grid, n_iter=100, cv=inner_cv, scoring='accuracy', random_state=13, n_jobs=-1)\n","\n","\n","from sklearn.metrics import f1_score, accuracy_score\n","best_scores = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_20 = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_25 = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_30 = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_35 = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_40 = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_scores_45 = {'accuracy': [], 'f2': [], 'f1':[]}\n","\n","for train_idx, test_idx in outer_cv.split(X, Y):\n","    X_train, X_test, X_test_20, X_test_25, X_test_30, X_test_35, X_test_40, X_test_45 = X[train_idx], X[test_idx], X_20[test_idx], X_25[test_idx], X_30[test_idx], X_35[test_idx], X_40[test_idx], X_45[test_idx]\n","    y_train, y_test, y_test_20, y_test_25, y_test_30, y_test_35, y_test_40, y_test_45 = Y[train_idx], Y[test_idx], Y_20[test_idx], Y_25[test_idx], Y_30[test_idx], Y_35[test_idx], Y_40[test_idx], Y_45[test_idx]\n","\n","    grid_search.fit(X_train, y_train)\n","\n","    y_pred = grid_search.predict(X_test)\n","    y_pred_20 = grid_search.predict(X_test_20)\n","    y_pred_25 = grid_search.predict(X_test_25)\n","    y_pred_30 = grid_search.predict(X_test_30)\n","    y_pred_35 = grid_search.predict(X_test_35)\n","    y_pred_40 = grid_search.predict(X_test_40)\n","    y_pred_45 = grid_search.predict(X_test_45)\n","\n","    f2 = fbeta_score(y_test, y_pred, beta=2)\n","    f2_20 = fbeta_score(y_test_20, y_pred_20, beta=2)\n","    f2_25 = fbeta_score(y_test_25, y_pred_25, beta=2)\n","    f2_30 = fbeta_score(y_test_30, y_pred_30, beta=2)\n","    f2_35 = fbeta_score(y_test_35, y_pred_35, beta=2)\n","    f2_40 = fbeta_score(y_test_40, y_pred_40, beta=2)\n","    f2_45 = fbeta_score(y_test_45, y_pred_45, beta=2)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    accuracy_20 = accuracy_score(y_test_20, y_pred_20)\n","    accuracy_25 = accuracy_score(y_test_25, y_pred_25)\n","    accuracy_30 = accuracy_score(y_test_30, y_pred_30)\n","    accuracy_35 = accuracy_score(y_test_35, y_pred_35)\n","    accuracy_40 = accuracy_score(y_test_40, y_pred_40)\n","    accuracy_45 = accuracy_score(y_test_45, y_pred_45)\n","\n","    f1 = f1_score(y_test, y_pred)\n","    f1_20 = f1_score(y_test_20, y_pred_20)\n","    f1_25 = f1_score(y_test_25, y_pred_25)\n","    f1_30 = f1_score(y_test_30, y_pred_30)\n","    f1_35 = f1_score(y_test_35, y_pred_35)\n","    f1_40 = f1_score(y_test_40, y_pred_40)\n","    f1_45 = f1_score(y_test_45, y_pred_45)\n","\n","    best_scores['f2'].append(f2)\n","    best_scores_20['f2'].append(f2_20)\n","    best_scores_25['f2'].append(f2_25)\n","    best_scores_30['f2'].append(f2_30)\n","    best_scores_35['f2'].append(f2_35)\n","    best_scores_40['f2'].append(f2_40)\n","    best_scores_45['f2'].append(f2_45)\n","\n","    best_scores['f1'].append(f1)\n","    best_scores_20['f1'].append(f1_20)\n","    best_scores_25['f1'].append(f1_25)\n","    best_scores_30['f1'].append(f1_30)\n","    best_scores_35['f1'].append(f1_35)\n","    best_scores_40['f1'].append(f1_40)\n","    best_scores_45['f1'].append(f1_45)\n","\n","    best_scores['accuracy'].append(accuracy)\n","    best_scores_20['accuracy'].append(accuracy_20)\n","    best_scores_25['accuracy'].append(accuracy_25)\n","    best_scores_30['accuracy'].append(accuracy_30)\n","    best_scores_35['accuracy'].append(accuracy_35)\n","    best_scores_40['accuracy'].append(accuracy_40)\n","    best_scores_45['accuracy'].append(accuracy_45)\n"],"metadata":{"id":"HANE6y7ngc8G","executionInfo":{"status":"ok","timestamp":1691587643352,"user_tz":-210,"elapsed":288394,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["average_best_scores = {scoring: np.mean(scores) for scoring, scores in best_scores.items()}\n","average_best_scores_20 = {scoring: np.mean(scores) for scoring, scores in best_scores_20.items()}\n","average_best_scores_25 = {scoring: np.mean(scores) for scoring, scores in best_scores_25.items()}\n","average_best_scores_30 = {scoring: np.mean(scores) for scoring, scores in best_scores_30.items()}\n","average_best_scores_35 = {scoring: np.mean(scores) for scoring, scores in best_scores_35.items()}\n","average_best_scores_40 = {scoring: np.mean(scores) for scoring, scores in best_scores_40.items()}\n","average_best_scores_45 = {scoring: np.mean(scores) for scoring, scores in best_scores_45.items()}\n","\n","print(f\"Average best scores: {average_best_scores}\")\n","print(f\"Average best scores_20: {average_best_scores_20}\")\n","print(f\"Average best scores_25: {average_best_scores_25}\")\n","print(f\"Average best scores_30: {average_best_scores_30}\")\n","print(f\"Average best scores_35: {average_best_scores_35}\")\n","print(f\"Average best scores_40: {average_best_scores_40}\")\n","print(f\"Average best scores_45: {average_best_scores_45}\")"],"metadata":{"id":"RezcTekqOGtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691587643357,"user_tz":-210,"elapsed":0,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"23e00ff2-2eae-4566-af03-ed4100a9de49"},"execution_count":13,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Average best scores: {'accuracy': 0.9950036911265319, 'f2': 0.9904077824797547, 'f1': 0.9921881517152151}\n","Average best scores_20: {'accuracy': 0.7044492839214529, 'f2': 0.20467976596369208, 'f1': 0.27301515832956635}\n","Average best scores_25: {'accuracy': 0.7175136571681678, 'f2': 0.26062533679488675, 'f1': 0.3363882686385283}\n","Average best scores_30: {'accuracy': 0.7390395688764211, 'f2': 0.3259586955145359, 'f1': 0.41114358491078}\n","Average best scores_35: {'accuracy': 0.7517230178650525, 'f2': 0.36166746090635976, 'f1': 0.4499636783800155}\n","Average best scores_40: {'accuracy': 0.7740129927653919, 'f2': 0.4240420445918149, 'f1': 0.5168722212102255}\n","Average best scores_45: {'accuracy': 0.7920751513361878, 'f2': 0.48493005514395227, 'f1': 0.5741057761047204}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import openpyxl\n","model = ['LR', 'LDA', 'SVM', 'KNN', 'XGBoost', 'RF']\n","FS = ['ANOVA', 'MI', 'Pearson', 'Chi2']\n","# Load the existing file\n","book = openpyxl.load_workbook('DWT_Results.xlsx')\n","book_20 = openpyxl.load_workbook('DWT_Results_20.xlsx')\n","book_25 = openpyxl.load_workbook('DWT_Results_25.xlsx')\n","book_30 = openpyxl.load_workbook('DWT_Results_30.xlsx')\n","book_35 = openpyxl.load_workbook('DWT_Results_35.xlsx')\n","book_40 = openpyxl.load_workbook('DWT_Results_40.xlsx')\n","book_45 = openpyxl.load_workbook('DWT_Results_45.xlsx')\n","\n","# Prepare the data to be written\n","data_acc = average_best_scores['accuracy']\n","data_acc_20 = average_best_scores_20['accuracy']\n","data_acc_25 = average_best_scores_25['accuracy']\n","data_acc_30 = average_best_scores_30['accuracy']\n","data_acc_35 = average_best_scores_35['accuracy']\n","data_acc_40 = average_best_scores_40['accuracy']\n","data_acc_45 = average_best_scores_45['accuracy']\n","\n","data_f2 = average_best_scores['f2']\n","data_f2_20 = average_best_scores_20['f2']\n","data_f2_25 = average_best_scores_25['f2']\n","data_f2_30 = average_best_scores_30['f2']\n","data_f2_35 = average_best_scores_35['f2']\n","data_f2_40 = average_best_scores_40['f2']\n","data_f2_45 = average_best_scores_45['f2']\n","\n","data_f1 = average_best_scores['f1']\n","data_f1_20 = average_best_scores_20['f1']\n","data_f1_25 = average_best_scores_25['f1']\n","data_f1_30 = average_best_scores_30['f1']\n","data_f1_35 = average_best_scores_35['f1']\n","data_f1_40 = average_best_scores_40['f1']\n","data_f1_45 = average_best_scores_45['f1']\n","\n","# Get the existing sheets\n","sheet_acc = book['ACC']\n","sheet_acc_20 = book_20['ACC']\n","sheet_acc_25 = book_25['ACC']\n","sheet_acc_30 = book_30['ACC']\n","sheet_acc_35 = book_35['ACC']\n","sheet_acc_40 = book_40['ACC']\n","sheet_acc_45 = book_45['ACC']\n","\n","sheet_f2 = book['F2']\n","sheet_f2_20 = book_20['F2']\n","sheet_f2_25 = book_25['F2']\n","sheet_f2_30 = book_30['F2']\n","sheet_f2_35 = book_35['F2']\n","sheet_f2_40 = book_40['F2']\n","sheet_f2_45 = book_45['F2']\n","\n","sheet_f1 = book['F1']\n","sheet_f1_20 = book_20['F1']\n","sheet_f1_25 = book_25['F1']\n","sheet_f1_30 = book_30['F1']\n","sheet_f1_35 = book_35['F1']\n","sheet_f1_40 = book_40['F1']\n","sheet_f1_45 = book_45['F1']\n","\n","# Calculate the correct row and column numbers\n","row = model.index('RF') + 2  # +2 because Excel index starts from 1 and row 1 contains headers\n","col = FS.index('Pearson') + 2  # +2 because Excel index starts from 1 and column 1 contains headers\n","\n","# Write to the ACC sheet\n","sheet_acc.cell(row=row, column=col, value=data_acc)\n","sheet_acc_20.cell(row=row, column=col, value=data_acc_20)\n","sheet_acc_25.cell(row=row, column=col, value=data_acc_25)\n","sheet_acc_30.cell(row=row, column=col, value=data_acc_30)\n","sheet_acc_35.cell(row=row, column=col, value=data_acc_35)\n","sheet_acc_40.cell(row=row, column=col, value=data_acc_40)\n","sheet_acc_45.cell(row=row, column=col, value=data_acc_45)\n","\n","# Write to the F2 sheet\n","sheet_f2.cell(row=row, column=col, value=data_f2)\n","sheet_f2_20.cell(row=row, column=col, value=data_f2_20)\n","sheet_f2_25.cell(row=row, column=col, value=data_f2_25)\n","sheet_f2_30.cell(row=row, column=col, value=data_f2_30)\n","sheet_f2_35.cell(row=row, column=col, value=data_f2_35)\n","sheet_f2_40.cell(row=row, column=col, value=data_f2_40)\n","sheet_f2_45.cell(row=row, column=col, value=data_f2_45)\n","\n","# Write to the F1 sheet\n","sheet_f1.cell(row=row, column=col, value=data_f1)\n","sheet_f1_20.cell(row=row, column=col, value=data_f1_20)\n","sheet_f1_25.cell(row=row, column=col, value=data_f1_25)\n","sheet_f1_30.cell(row=row, column=col, value=data_f1_30)\n","sheet_f1_35.cell(row=row, column=col, value=data_f1_35)\n","sheet_f1_40.cell(row=row, column=col, value=data_f1_40)\n","sheet_f1_45.cell(row=row, column=col, value=data_f1_45)\n","\n","# Save and close the Excel file\n","book.save('DWT_Results.xlsx')\n","book_20.save('DWT_Results_20.xlsx')\n","book_25.save('DWT_Results_25.xlsx')\n","book_30.save('DWT_Results_30.xlsx')\n","book_35.save('DWT_Results_35.xlsx')\n","book_40.save('DWT_Results_40.xlsx')\n","book_45.save('DWT_Results_45.xlsx')\n"],"metadata":{"id":"DlKFOdkwcoE6","executionInfo":{"status":"ok","timestamp":1691587652666,"user_tz":-210,"elapsed":9313,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}}},"execution_count":14,"outputs":[]}]}