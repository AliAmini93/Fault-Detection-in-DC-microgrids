{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1sW_CxHM8NQtdb6QaW-pKACzPEXRrObw8","authorship_tag":"ABX9TyND/VNJn8E5R6cr60Zg9gto"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eH14YbVJF2jJ","executionInfo":{"status":"ok","timestamp":1690546811026,"user_tz":-210,"elapsed":16,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"e098b731-030a-4a09-e691-2b7184780b22"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Ali Sobhani Thesis/FFT\n"]}],"source":["cd '/content/drive/MyDrive/Ali Sobhani Thesis/FFT'"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold, GridSearchCV\n","from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from scipy.stats import pearsonr\n","from sklearn.metrics import fbeta_score\n","\n","X = np.load('X.npy')\n","Y = np.load('Y.npy')\n","\n","\n","\n","feature_selection = SelectKBest(score_func=mutual_info_classif)\n","feature_names = ['IP1_C1', 'IP1_C2', 'IP1_C3','IP1_C4','IN1_C1', 'IN1_C2', 'IN1_C3', 'IN1_C4',\n","                    'IP2_C1', 'IP2_C2', 'IP2_C3', 'IP2_C4', 'IN2_C1', 'IN2_C2', 'IN2_C3', 'IN2_C4',\n","                    'VP1_C1', 'VP1_C2', 'VP1_C3', 'VP1_C4', 'VN1_C1', 'VN1_C2', 'VN1_C3', 'VN1_C4',\n","                    'VP2_C1', 'VP2_C2', 'VP2_C3', 'VP2_C4', 'VN2_C1', 'VN2_C2', 'VN2_C3', 'VN2_C4']\n","\n","svc = SVC()\n","\n","pipeline = Pipeline([\n","    ('feature_selection', feature_selection),\n","    ('svc', svc)\n","])\n","\n","param_grid = {\n","    'feature_selection__k': list(range(1, X.shape[1] + 1)),\n","    'svc__C': [0.1, 1, 10],\n","    'svc__kernel': ['linear', 'poly', 'rbf'],\n","    'svc__gamma': ['scale', 'auto'],\n","    'svc__degree': [2, 3, 4, 5]\n","}\n","\n","outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n","inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=13)\n","\n","# Initialize HalvingGridSearchCV with accuracy as the scoring metric\n","grid_search = HalvingGridSearchCV(pipeline, param_grid, cv=inner_cv, scoring='accuracy')\n","\n","# Lists to store results for each fold\n","best_scores = {'accuracy': [], 'f2': [], 'f1':[]}\n","best_params = []\n","all_selected_names = []\n","\n","for train_idx, test_idx in outer_cv.split(X, Y):\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = Y[train_idx], Y[test_idx]\n","\n","    # Fit the model and get the best parameters\n","    grid_search.fit(X_train, y_train)\n","    best_params.append(grid_search.best_params_)\n","\n","    # Append the best accuracy score\n","    #best_scores['accuracy'].append(grid_search.best_score_)\n","\n","    # Predict the test set results\n","    y_pred = grid_search.predict(X_test)\n","\n","    # Calculate the F2 score and append it to the list\n","    f2 = fbeta_score(y_test, y_pred, beta=2)\n","    ################################\n","    from sklearn.metrics import f1_score, accuracy_score\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    ################################\n","    best_scores['f2'].append(f2)\n","    best_scores['f1'].append(f1)\n","    best_scores['accuracy'].append(accuracy)\n","\n","    # Get the selected features\n","    selected_features = grid_search.best_estimator_.named_steps['feature_selection']\n","    selected_names = [feature_names[i] for i in selected_features.get_support(indices=True)]\n","    all_selected_names.append(selected_names)\n","\n","# Print and store the average best score\n","average_best_scores = {scoring: np.mean(scores) for scoring, scores in best_scores.items()}\n","print(f\"Average best scores: {average_best_scores}\")\n","\n"],"metadata":{"id":"WYiiMD9oGuV0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690550306299,"user_tz":-210,"elapsed":1472427,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"d5bf18f8-749f-486f-d4dd-4c0001401099"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n","2304 fits failed out of a total of 4608.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","2304 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n","    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 201, in fit\n","    y = self._validate_targets(y)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 749, in _validate_targets\n","    raise ValueError(\n","ValueError: The number of classes has to be greater than one; got 1 class\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.95454545 0.90909091 0.90909091]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.95833333 0.95833333 0.86742424]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.73095238 0.74603175 0.81666667]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.79047619 0.8031746  0.84603175]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [      nan       nan       nan ... 0.9953271 1.        1.       ]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ...  1.  1.  1.]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.99845679 1.         1.        ]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ...  1.  1.  1.]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ...  1.  1.  1.]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ...  1.  1.  1.]\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Average best scores: {'accuracy': 1.0, 'f2': 1.0}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import openpyxl\n","model = ['LR', 'LDA', 'SVM', 'KNN', 'XGBoost', 'RF']\n","FS = ['ANOVA', 'MI', 'Pearson', 'Chi2']\n","# Load the existing file\n","book = openpyxl.load_workbook('FFT_Results.xlsx')\n","\n","# Prepare the data to be written\n","data_acc = average_best_scores['accuracy']\n","data_f2 = average_best_scores['f2']\n","data_f1 = average_best_scores['f1']\n","\n","# Get the existing sheets\n","sheet_acc = book['ACC']\n","sheet_f2 = book['F2']\n","sheet_f1 = book['F1']\n","\n","# Calculate the correct row and column numbers\n","row = model.index('SVM') + 2  # +2 because Excel index starts from 1 and row 1 contains headers\n","col = FS.index('MI') + 2  # +2 because Excel index starts from 1 and column 1 contains headers\n","\n","# Write to the ACC sheet\n","sheet_acc.cell(row=row, column=col, value=data_acc)\n","\n","# Write to the F2 sheet\n","sheet_f2.cell(row=row, column=col, value=data_f2)\n","\n","# Write to the F1 sheet\n","sheet_f1.cell(row=row, column=col, value=data_f1)\n","\n","# Save and close the Excel file\n","book.save('FFT_Results.xlsx')"],"metadata":{"id":"pgIsyql4W2MN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pickle\n","\n","# Specify the directory path\n","dir_path = '/content/drive/MyDrive/Ali Sobhani Thesis/FFT/MI/SVM'\n","\n","# Save best_params and all_selected_names to the directory\n","with open(os.path.join(dir_path, 'best_params.pkl'), 'wb') as f:\n","    pickle.dump(best_params, f)\n","with open(os.path.join(dir_path, 'all_selected_names.pkl'), 'wb') as f:\n","    pickle.dump(all_selected_names, f)"],"metadata":{"id":"gF1DPMrncA_c"},"execution_count":null,"outputs":[]}]}